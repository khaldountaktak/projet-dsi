{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f1ee6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/khaldoun/prjt_vap\n",
      "Python path configured\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ajouter le repertoire racine au path\n",
    "project_root = Path('/home/khaldoun/prjt_vap')\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python path configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da812a12",
   "metadata": {},
   "source": [
    "## Etape 1: Chargement des donnees\n",
    "\n",
    "On charge les 1,050 questions ISO depuis les fichiers CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4e58ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils.data_loader:Loaded 200 records from labeled_our_iso_27001.csv\n",
      "INFO:src.utils.data_loader:Loaded 250 records from labeled_our_iso_27002.csv\n",
      "INFO:src.utils.data_loader:Loaded 200 records from labeled_our_iso_27017.csv\n",
      "INFO:src.utils.data_loader:Loaded 200 records from labeled_our_iso_27018.csv\n",
      "INFO:src.utils.data_loader:Loaded 200 records from labeled_our_iso_27701.csv\n",
      "INFO:src.utils.data_loader:Loaded total of 1050 records from method 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de questions chargees: 1050\n",
      "Standards: ['iso_27001', 'iso_27002', 'iso_27017', 'iso_27018', 'iso_27701']\n",
      "\n",
      "Premiere question:\n",
      "Have you identified internal issues that affect your ISMS?\n"
     ]
    }
   ],
   "source": [
    "from src.utils.data_loader import ISODataLoader\n",
    "\n",
    "loader = ISODataLoader()\n",
    "data = loader.load_method_data(method=1)\n",
    "\n",
    "print(f\"Nombre de questions chargees: {len(data)}\")\n",
    "print(f\"Standards: {data['iso_standard'].unique().tolist()}\")\n",
    "print(f\"\\nPremiere question:\")\n",
    "print(data.iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecc05b5",
   "metadata": {},
   "source": [
    "## Etape 2: Generation des embeddings\n",
    "\n",
    "On utilise le modele all-MiniLM-L6-v2 pour generer des embeddings de 384 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78340a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_traditional.embeddings:Loading embedding model: all-MiniLM-L6-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32010233514e459998104c608feeafeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 \"HTTP/1.1 200 OK\"\n",
      "INFO:src.rag_traditional.embeddings:Model loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modele: all-MiniLM-L6-v2\n",
      "Dimension: 384\n"
     ]
    }
   ],
   "source": [
    "from src.rag_traditional.embeddings import EmbeddingGenerator\n",
    "\n",
    "embedding_gen = EmbeddingGenerator(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "print(f\"Modele: {embedding_gen.model_name}\")\n",
    "print(f\"Dimension: {embedding_gen.get_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19bbfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_traditional.embeddings:Generating embeddings for 3 texts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4795cf9b25ee430fab92aa0618208e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_traditional.embeddings:Generated embeddings with shape: (3, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape des embeddings: (3, 384)\n",
      "\n",
      "Similarite 'backup' vs 'disaster recovery': 0.3078\n",
      "Similarite 'backup' vs 'internal issues': 0.0757\n"
     ]
    }
   ],
   "source": [
    "# Test sur quelques exemples\n",
    "test_questions = [\n",
    "    \"Are backup procedures documented?\",\n",
    "    \"Is there a disaster recovery plan?\",\n",
    "    \"Have you identified internal issues?\"\n",
    "]\n",
    "\n",
    "embeddings = embedding_gen.embed_batch(test_questions, show_progress=True)\n",
    "print(f\"\\nShape des embeddings: {embeddings.shape}\")\n",
    "\n",
    "# Calcul de similarite\n",
    "sim1 = embedding_gen.compute_similarity(embeddings[0], embeddings[1])\n",
    "sim2 = embedding_gen.compute_similarity(embeddings[0], embeddings[2])\n",
    "\n",
    "print(f\"\\nSimilarite 'backup' vs 'disaster recovery': {sim1:.4f}\")\n",
    "print(f\"Similarite 'backup' vs 'internal issues': {sim2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c823a46",
   "metadata": {},
   "source": [
    "## Etape 3: Creation du vector store\n",
    "\n",
    "On stocke les embeddings dans ChromaDB pour la recherche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "367bdb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_traditional.vector_store:Vector store initialized at /home/khaldoun/prjt_vap/chroma_db\n",
      "INFO:src.rag_traditional.vector_store:Collection 'iso_questions_method_1' ready\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection: iso_questions_method_1\n",
      "Documents: 1050\n"
     ]
    }
   ],
   "source": [
    "from src.rag_traditional.vector_store import VectorStore\n",
    "\n",
    "vector_store = VectorStore(\n",
    "    persist_directory=\"/home/khaldoun/prjt_vap/chroma_db\",\n",
    "    collection_name=\"iso_questions_method_1\"\n",
    ")\n",
    "\n",
    "vector_store.create_collection(reset=False)\n",
    "stats = vector_store.get_collection_stats()\n",
    "\n",
    "print(f\"Collection: {stats['collection_name']}\")\n",
    "print(f\"Documents: {stats['document_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de5cd146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection deja indexee\n"
     ]
    }
   ],
   "source": [
    "# Si la collection est vide, on l'indexe\n",
    "if stats['document_count'] == 0:\n",
    "    print(\"Indexation des documents...\")\n",
    "    documents = loader.get_documents_for_rag(method=1)\n",
    "    \n",
    "    # Generer les embeddings\n",
    "    texts = [doc['content'] for doc in documents]\n",
    "    embeddings = embedding_gen.embed_batch(texts, show_progress=True)\n",
    "    \n",
    "    # Ajouter au vector store\n",
    "    for i, doc in enumerate(documents):\n",
    "        doc['embedding'] = embeddings[i]\n",
    "    \n",
    "    vector_store.add_documents(documents)\n",
    "    print(f\"\\nIndexation terminee: {len(documents)} documents\")\n",
    "else:\n",
    "    print(\"Collection deja indexee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679154a",
   "metadata": {},
   "source": [
    "## Etape 4: Recherche semantique\n",
    "\n",
    "On teste la recherche par similarite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bba14c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_traditional.retriever:Semantic retriever initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever initialise\n"
     ]
    }
   ],
   "source": [
    "from src.rag_traditional.retriever import SemanticRetriever\n",
    "\n",
    "retriever = SemanticRetriever(\n",
    "    vector_store=vector_store,\n",
    "    embedding_generator=embedding_gen\n",
    ")\n",
    "\n",
    "print(\"Retriever initialise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecb0f029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_traditional.retriever:Retrieving documents for query: 'Questions about data backups and recovery'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68d0ca9c89a49c1987c7ae2b0f54ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_traditional.retriever:Retrieved 5 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requete: 'Questions about data backups and recovery'\n",
      "Resultats trouves: 5\n",
      "\n",
      "[1] Score: 0.7733\n",
      "    Are backups of deleted data handled appropriately?\n",
      "    Standard: iso_27017\n",
      "\n",
      "[2] Score: 0.7067\n",
      "    Are backups performed according to policy?\n",
      "    Standard: iso_27002\n",
      "\n",
      "[3] Score: 0.7054\n",
      "    Are backups tested for restoration integrity?\n",
      "    Standard: iso_27002\n",
      "\n",
      "[4] Score: 0.6856\n",
      "    Are backups performed according to schedule?\n",
      "    Standard: iso_27001\n",
      "\n",
      "[5] Score: 0.6814\n",
      "    Are cloud recovery procedures documented?\n",
      "    Standard: iso_27017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Recherche simple\n",
    "query = \"Questions about data backups and recovery\"\n",
    "results = retriever.retrieve(query, top_k=5)\n",
    "\n",
    "print(f\"Requete: '{query}'\")\n",
    "print(f\"Resultats trouves: {len(results)}\\n\")\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"[{i}] Score: {doc['score']:.4f}\")\n",
    "    print(f\"    {doc['content']}\")\n",
    "    print(f\"    Standard: {doc['metadata']['iso_standard']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce6fe744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_traditional.retriever:Retrieving documents for query: 'Security policy and risk management'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed627636052247628a77de9740a91023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_traditional.retriever:Retrieved 5 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requete: 'Security policy and risk management' (filtre: ISO 27001)\n",
      "Resultats: 5\n",
      "\n",
      "[1] Are information security policies approved by management?...\n",
      "    Clause: A.5 – Information Security Policies\n",
      "\n",
      "[2] Are employees aware of security policies?...\n",
      "    Clause: Clause 7 – Support\n",
      "\n",
      "[3] Are information security policies communicated to all staff?...\n",
      "    Clause: A.5 – Information Security Policies\n",
      "\n",
      "[4] Are information security policies documented and maintained?...\n",
      "    Clause: A.5 – Information Security Policies\n",
      "\n",
      "[5] Is there a documented information security policy?...\n",
      "    Clause: Clause 5 – Leadership\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Recherche avec filtre\n",
    "query2 = \"Security policy and risk management\"\n",
    "results2 = retriever.retrieve(\n",
    "    query=query2,\n",
    "    filter_standard=\"iso_27001\",\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(f\"Requete: '{query2}' (filtre: ISO 27001)\")\n",
    "print(f\"Resultats: {len(results2)}\\n\")\n",
    "\n",
    "for i, doc in enumerate(results2, 1):\n",
    "    print(f\"[{i}] {doc['content'][:80]}...\")\n",
    "    print(f\"    Clause: {doc['metadata']['title']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f4f19b",
   "metadata": {},
   "source": [
    "## Etape 5: Generation avec LLM\n",
    "\n",
    "On utilise Ollama avec Mistral pour generer des reponses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b752f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.llm.llm_interface:Initialized Ollama LLM with model: mistral\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Ollama initialise avec Mistral\n"
     ]
    }
   ],
   "source": [
    "from src.llm.llm_interface import LLMFactory\n",
    "\n",
    "llm = LLMFactory.create_llm(\n",
    "    provider=\"ollama\",\n",
    "    model=\"mistral\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "print(\"LLM Ollama initialise avec Mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fea3d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test LLM:  Bonjour signifie \"hello\" en français.\n"
     ]
    }
   ],
   "source": [
    "# Test de generation simple\n",
    "test_response = llm.generate(\"Dis bonjour en francais\")\n",
    "print(f\"Test LLM: {test_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b385b9",
   "metadata": {},
   "source": [
    "## Etape 6: Systeme RAG complet\n",
    "\n",
    "On teste le systeme complet de bout en bout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a99e8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_traditional.query_handler:Initializing ISO RAG System...\n",
      "INFO:src.rag_traditional.query_handler:Loading data...\n",
      "INFO:src.rag_traditional.query_handler:Initializing embedding model...\n",
      "INFO:src.rag_traditional.embeddings:Loading embedding model: all-MiniLM-L6-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50552d68b6c9490f8cd8e83afded4afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 \"HTTP/1.1 200 OK\"\n",
      "INFO:src.rag_traditional.embeddings:Model loaded successfully\n",
      "INFO:src.rag_traditional.query_handler:Initializing vector store...\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:src.rag_traditional.vector_store:Vector store initialized at /home/khaldoun/prjt_vap/chroma_db\n",
      "INFO:src.rag_traditional.query_handler:Initializing LLM...\n",
      "INFO:src.llm.llm_interface:Initialized Ollama LLM with model: mistral\n",
      "INFO:src.rag_traditional.vector_store:Collection 'iso_questions_method_1' ready\n",
      "INFO:src.rag_traditional.query_handler:Initializing retriever...\n",
      "INFO:src.rag_traditional.retriever:Semantic retriever initialized\n",
      "INFO:src.rag_traditional.query_handler:OK - ISO RAG System initialized successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Systeme RAG complet initialise\n"
     ]
    }
   ],
   "source": [
    "from src.rag_traditional.query_handler import ISORAGSystem\n",
    "\n",
    "rag_system = ISORAGSystem(\n",
    "    data_method=1,\n",
    "    embedding_model=\"all-MiniLM-L6-v2\",\n",
    "    llm_provider=\"ollama\",\n",
    "    llm_model=\"mistral\",\n",
    "    rebuild_index=False\n",
    ")\n",
    "\n",
    "print(\"Systeme RAG complet initialise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54a9fce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_traditional.query_handler:Processing query: 'Backups and disaster recovery procedures'\n",
      "INFO:src.rag_traditional.retriever:Retrieving documents for query: 'Backups and disaster recovery procedures'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52b3de62e484bda9101127ec0584279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_traditional.retriever:Retrieved 5 documents\n",
      "INFO:src.rag_traditional.query_handler:Retrieved 5 relevant documents\n",
      "INFO:src.rag_traditional.query_handler:Generating response with LLM...\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESULTAT GENERATION RAG\n",
      "================================================================================\n",
      "\n",
      "Requete: Backups and disaster recovery procedures\n",
      "\n",
      "Documents recuperes: 5\n",
      "\n",
      "Reponse generee:\n",
      "\n",
      " Title: Backup and Disaster Recovery Procedures Questionnaire (Based on ISO 27002 and ISO 27017)\n",
      "\n",
      "1. Are disaster recovery procedures automated where possible? (ISO 27002, Clause: Extended – Continuity & Resilience, Labels: automation, procedures, documentation, updates)\n",
      "\n",
      "2. Are backups performed according to policy? (ISO 27002, Clause: 12.3 Backup, Labels: backups, policy compliance)\n",
      "\n",
      "3. Are backups tested for restoration integrity? (ISO 27002, Clause: 12.3 Backup, Labels: backup protection, backup integrity, resilience, backups, policy compliance)\n",
      "\n",
      "4. Are backups of deleted data handled appropriately? (ISO 27017, Clause: 27017 – Cloud Data Deletion, Labels: cloud security, governance, compliance, risk management)\n",
      "\n",
      "5. Is cloud Business Continuity Plan (BCP) aligned with CSP disaster recovery capabilities? (ISO 27017, Clause: 27017 – Cloud Continuity & Availability, Labels: cloud security)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test de generation de questionnaire\n",
    "query = \"Backups and disaster recovery procedures\"\n",
    "\n",
    "result = rag_system.query(\n",
    "    user_query=query,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RESULTAT GENERATION RAG\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nRequete: {query}\\n\")\n",
    "print(f\"Documents recuperes: {result['num_sources']}\")\n",
    "print(f\"\\nReponse generee:\\n\")\n",
    "print(result['answer'])\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "187da833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_traditional.query_handler:Processing query: 'Security policy and employee training'\n",
      "INFO:src.rag_traditional.retriever:Retrieving documents for query: 'Security policy and employee training'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa8cc249c234b47a79fbf2b9a8a41d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_traditional.retriever:Retrieved 5 documents\n",
      "INFO:src.rag_traditional.query_handler:Retrieved 5 relevant documents\n",
      "INFO:src.rag_traditional.query_handler:Generating response with LLM...\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 2\n",
      "================================================================================\n",
      "\n",
      "Requete: Security policy and employee training\n",
      "\n",
      " Title: ISO 27001 Security Policy and Employee Training Questionnaire\n",
      "\n",
      "1. Standard: ISO_27001 (Clause A.7 – Human Resource Security)\n",
      "   - Are security policies provided to new employees during onboarding?\n",
      "   - Labels: employee awareness, security policies, security training\n",
      "\n",
      "2. Standard: ISO_27001 (Clause 7 – Support)\n",
      "   - Are employees aware of the organization's security policies?\n",
      "   - Labels: employee awareness, security policies, security training, security responsibilities\n",
      "\n",
      "3. Standard: ISO_27001 (Clause 7 – Support)\n",
      "   - Is annual security awareness training conducted for employees?\n",
      "   - Labels: documentation, monitoring, risk management, policy compliance\n",
      "\n",
      "4. Standard: ISO_27001 (Clause 7 – Support)\n",
      "   - Do employees understand their security responsibilities as outlined in the organization's policies?\n",
      "   - Labels: employee awareness, security policies, security training, security responsibilities\n",
      "\n",
      "5. Standard: ISO_27002 (Clause 7.2 During Employment)\n",
      "   - Are employees trained in their security responsibilities?\n",
      "   - Labels: security awareness training, employee training, security responsibilities, workplace security\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Generation avec un autre sujet\n",
    "query2 = \"Security policy and employee training\"\n",
    "\n",
    "result2 = rag_system.query(\n",
    "    user_query=query2,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 2\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nRequete: {query2}\\n\")\n",
    "print(result2['answer'])\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36337ce",
   "metadata": {},
   "source": [
    "## Statistiques finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ba97f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils.data_loader:Loaded 200 records from labeled_our_iso_27001.csv\n",
      "INFO:src.utils.data_loader:Loaded 250 records from labeled_our_iso_27002.csv\n",
      "INFO:src.utils.data_loader:Loaded 200 records from labeled_our_iso_27017.csv\n",
      "INFO:src.utils.data_loader:Loaded 200 records from labeled_our_iso_27018.csv\n",
      "INFO:src.utils.data_loader:Loaded 200 records from labeled_our_iso_27701.csv\n",
      "INFO:src.utils.data_loader:Loaded total of 1050 records from method 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATISTIQUES DU SYSTEME RAG VECTORIEL\n",
      "==================================================\n",
      "Methode de donnees: 1\n",
      "Documents indexes: 1050\n",
      "Modele d'embedding: all-MiniLM-L6-v2\n",
      "Dimension: 384\n",
      "Provider LLM: Ollama\n",
      "Modele LLM: Mistral\n"
     ]
    }
   ],
   "source": [
    "stats = rag_system.get_statistics()\n",
    "\n",
    "print(\"STATISTIQUES DU SYSTEME RAG VECTORIEL\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Methode de donnees: {rag_system.data_method}\")\n",
    "print(f\"Documents indexes: {stats['vector_store']['document_count']}\")\n",
    "print(f\"Modele d'embedding: {stats['embedding_model']}\")\n",
    "print(f\"Dimension: {stats['embedding_dimension']}\")\n",
    "print(f\"Provider LLM: Ollama\")\n",
    "print(f\"Modele LLM: Mistral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689698e7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "La methode vectorielle fonctionne bien pour:\n",
    "- Recherche semantique rapide\n",
    "- Requetes simples\n",
    "- Bonne precision sur les similarites\n",
    "\n",
    "**Temps d'execution:** ~20-30 secondes apres indexation initiale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
